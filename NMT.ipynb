{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NMT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcSUCVHBiKGu"
      },
      "source": [
        "## Neural Machine Translation  with attention practice on french to english DS\n",
        "\n",
        "### Code is heavily based on the tensorflow tutorial found at this link\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/nmt_with_attention\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg-HWN9-UWGb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, Softmax, Embedding, GRU\n",
        "from tensorflow.keras import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import unicodedata\n",
        "import os\n",
        "import re\n",
        "\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
        "TF_FORCE_GPU_ALLOW_GROWTH=1\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRffQZ1w2ybu"
      },
      "source": [
        "os.chdir(\"./drive/MyDrive/Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqxn3-5VWdlr"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjs7ciuXWc3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff36f3b-67cf-4a5e-e324-1a2f6743aabf"
      },
      "source": [
        "url = 'http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip'\n",
        "raw_data_path = tf.keras.utils.get_file(\n",
        "          \"eng_french_raw_data\",\n",
        "          url,\n",
        "          extract=True)\n",
        "\n",
        "data_path = os.path.join(os.path.dirname(raw_data_path), 'fra.txt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\n",
            "3424256/3423204 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwSCqTc-W9wg"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0FMBagrYxLE"
      },
      "source": [
        "# preserve accents\n",
        "def normalize_unicode(s):\n",
        "  \"\"\" Used to preserve characters with accents \"\"\"\n",
        "  return ''.join(c for c in unicodedata.normalize('NFC', s))\n",
        "\n",
        "# delete accents\n",
        "def normalize_unicode(s)\n",
        "  \"\"\" Used to delete characters with accents \"\"\"\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def read_file(path):\n",
        "  with open(path, \"r\", encoding=\"UTF-8\") as f:\n",
        "    return f.read()\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  # punctuations to preserve (\".\", \"?\", \"!\", \",\")\n",
        "  \n",
        "  # lower the case\n",
        "  w = w.lower()\n",
        "  \n",
        "  # normalize unicode \n",
        "  w = normalize_unicode(w)\n",
        "\n",
        "  # padding punctuation with spaces\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([.!,?])\", r\" \\1 \", w)\n",
        "\n",
        "  # replace long white spaces with a single space\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, punctuations to save)\n",
        "  #w = re.sub(r\"[^a-z.!,'?]+\", \" \", w)\n",
        "\n",
        "  # remove strip trailing and ending spaces\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w\n",
        "\n",
        "\n",
        "def tokenize(list_of_sentences):\n",
        "  tokenizer = Tokenizer(filters='',\n",
        "                        split=' ', \n",
        "                        char_level=False,\n",
        "                        oov_token=\"<oov>\")\n",
        "  tokenizer.fit_on_texts(list_of_sentences)\n",
        "  tokenized_sentences = tokenizer.texts_to_sequences(list_of_sentences)\n",
        "  tokenized_sentences = pad_sequences(tokenized_sentences, padding='post')\n",
        "\n",
        "  return tokenized_sentences, tokenizer\n",
        "\n",
        "\n",
        "def preprocess_data(path, train_split=0.8, dataset_fraction=0.2):\n",
        "  \"\"\"\n",
        "    preprocess data\n",
        "\n",
        "    Adjust dataset_fraction to increase or reduce dataset and subsequently\n",
        "    vocabulary size depending on compute resources\n",
        "\n",
        "    Args:\n",
        "      path (str): path to text file / data\n",
        "      train_split (float): train/test split\n",
        "      dataset_fraction (float): fraction of the full dataset to train on\n",
        "\n",
        "    Return:\n",
        "      (tuple): lists with train and test sentences of source and target \n",
        "                languages with their tokenizers \n",
        "  \"\"\"\n",
        "  # read data \n",
        "  input_data_as_string = read_file(path)\n",
        "\n",
        "  # preprocess data for tokenizer - list of list of sentences\n",
        "  input_data = [[preprocess_sentence(sentence) for sentence in line.split(\"\\t\")] \\\n",
        "                  for line in input_data_as_string.split(\"\\n\")\\\n",
        "                  if len(line.split(\"\\t\")) == 2]\n",
        "\n",
        "  english_sentences, target_lang_sentences = list(zip(*input_data))\n",
        "  size_of_data = len(english_sentences)\n",
        "  data_indices = np.arange(size_of_data)\n",
        "  np.random.shuffle(data_indices)\n",
        "  data_indices = data_indices[:int(size_of_data * dataset_fraction)]\n",
        "  split_point = int(train_split * len(data_indices))\n",
        "  train_idx, test_idx = data_indices[:split_point], data_indices[split_point:]\n",
        "  \n",
        "  # tokenize\n",
        "  tokenized_english_sentences, english_tokenizer = tokenize(english_sentences)\n",
        "  tokenized_target_lang_sentences, target_lang_tokenizer = tokenize(target_lang_sentences)\n",
        "\n",
        "  return  tokenized_english_sentences[train_idx], \\\n",
        "          tokenized_english_sentences[test_idx], \\\n",
        "          tokenized_target_lang_sentences[train_idx], \\\n",
        "          tokenized_target_lang_sentences[test_idx], \\\n",
        "          english_tokenizer, \\\n",
        "          target_lang_tokenizer\n",
        "\n",
        "\n",
        "def display_sample_sentences(num_of_samples, \n",
        "                             tokenized_english_sentences,\n",
        "                             tokenized_target_lang_sentences,\n",
        "                             english_tokenizer,\n",
        "                             target_lang_tokenizer,\n",
        "                             target_lang=\"French\"):\n",
        "  num_of_words_not_oov = np.sum(tokenized_english_sentences != 0, axis=1)\n",
        "  indices_of_top_words_in_vocab = np.argsort(num_of_words_not_oov)[::-1][:num_of_samples]\n",
        "  sample_english_tokens = tokenized_english_sentences[indices_of_top_words_in_vocab]\n",
        "  sample_target_lang_tokens = tokenized_target_lang_sentences[indices_of_top_words_in_vocab]\n",
        "  sample_english_sentences = english_tokenizer.sequences_to_texts(sample_english_tokens)\n",
        "  sample_target_lang_sentences = target_lang_tokenizer.sequences_to_texts(sample_target_lang_tokens)\n",
        "  for eng, targ_lang in zip(sample_english_sentences, sample_target_lang_sentences):\n",
        "    print(f\"English: {eng}\")\n",
        "    print(f\"{target_lang}: {targ_lang} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1aXrx7B8wFc"
      },
      "source": [
        "train_eng_sen, test_eng_sen, train_french_sen, test_french_sen,\\\n",
        "          english_tokenizer, french_tokenizer = preprocess_data(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGf1vxN1B3AO",
        "outputId": "59837c06-c6a1-4aab-c14a-6ff98eb49b5a"
      },
      "source": [
        "display_sample_sentences(10,\n",
        "                         train_eng_sen,\n",
        "                         train_french_sen,\n",
        "                         english_tokenizer,\n",
        "                         french_tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: <start> it's still too hard to find a job . and even if you have a job , chances are you're having a tougher time paying the rising costs of everything from groceries to gas . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> c'est encore trop difficile de trouver un emploi . et meme quand on en a un , il y a des chances qu'on ait davantage de difficultes a payer le cout de tout , de l'epicerie au gaz . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> you may not learn to speak as well as a native speaker , but you should be able to speak well enough that native speakers will understand what you have to say . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> peut-etre n'apprendrez-vous pas a parler comme un locuteur natif , mais vous devriez etre en mesure de parler suffisamment bien pour que les natifs comprennent ce que vous avez a dire . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> a committee is a group of people who individually can do nothing , but who , as a group , can meet and decide that nothing can be done . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> un comite est un groupe de gens qui ne peuvent rien faire individuellement mais qui peuvent tenir des reunions en tant que groupe et parvenir a la decision qu'on ne peut rien faire . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> i know it's kind of late , but would you mind if i came over now ? i have something i need to discuss with you . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> je sais qu'il est assez tard mais cela te derangerait-il que je vienne chez toi maintenant ? j'ai quelque chose qu'il me faut discuter avec toi . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> a man touched down on the moon . a wall came down in berlin . a world was connected by our own science and imagination . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> un homme a atterri sur la lune . un mur a ete abattu a berlin . un monde a ete connecte par notre propre science et notre imagination . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> a good theory is characterized by the fact that it makes a number of predictions that could in principle be disproved or falsified by observation . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> une bonne theorie se caracterise par le fait de faire une serie de predictions qui , en principe , pourraient etre refutees ou mises en defaut par l'observation . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> a chance to do as we please , especially to do as little hard work as possible , is a secret desire of almost everybody . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> une occasion de faire ce qui nous plait , en particulier de faire aussi peu de travail penible que possible , est le desir secret de presque tout le monde . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> if you don't eat breakfast , you'll probably be hungry during the morning and won't be as efficient at work as you could be . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> si tu ne petit-dejeunes pas , tu auras probablement faim au cours de la matinee et tu ne seras pas aussi efficace au travail que tu pourrais l'etre . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> every time i make a mistake , i learn something . the challenge is not to keep making the same mistakes over and over . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> chaque fois que je commets une erreur , j'apprends quelque chose . le defi est de ne pas continuer a toujours commettre les memes erreurs . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n",
            "English: <start> according to the contract you may take three days of bereavement leave for your uncle's funeral , but only one for your nephew's . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov>\n",
            "French: <start> conformement au contrat , vous pouvez prendre trois jours de conge de deuil pour les funerailles de votre oncle , mais un seul pour celles de votre neveu . <end> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> <oov> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeV3Q-2rZl-7"
      },
      "source": [
        "## Batch Data and Hyperameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8jvzkOEZxGP"
      },
      "source": [
        "num_train, NUM_INP_TIMESTEPS = train_eng_sen.shape\n",
        "BUFFER_SIZE = num_train\n",
        "BATCH_SIZE = 32\n",
        "STEPS_PER_EPOCH = num_train//BATCH_SIZE\n",
        "EMBED_DIMS = 256\n",
        "UNITS = 1024\n",
        "ATTENTION_DIMS = 10\n",
        "VOCAB_INP_SIZE = len(english_tokenizer.word_index) + 1 #to account for padding\n",
        "VOCAB_TARG_SIZE = len(french_tokenizer.word_index) + 1\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 30\n",
        "\n",
        "sparse_cat_lossfn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_eng_sen, train_french_sen)).shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_eng_sen, test_french_sen)).shuffle(BUFFER_SIZE)\n",
        "test_data = test_data.batch(BATCH_SIZE)\n",
        "\n",
        "def loss_fn(targets, outputs, sparse_cat_lossfn=sparse_cat_lossfn):\n",
        "  loss = sparse_cat_lossfn(targets, outputs)\n",
        "  mask = tf.cast(targets != 0, loss.dtype)\n",
        "  return tf.reduce_mean(loss * mask)\n",
        "\n",
        "def disp_sentence(x):\n",
        "   return \" \".join(i for i in x.split(\" \") if i not in ['<start>', '<oov>', '<end>'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1gknCCSZt0n"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBtWVIy5Z6de"
      },
      "source": [
        "class AttentionLayer(tf.keras.Model):\n",
        "  def __init__(self, attention_hidden_dims):\n",
        "    super(AttentionLayer, self).__init__()\n",
        "    self.W1 = Dense(attention_hidden_dims)\n",
        "    self.W2 = Dense(attention_hidden_dims)\n",
        "    self.V = Dense(1)\n",
        "    self.softmax = Softmax(axis=1)\n",
        "\n",
        "  def call(self, query_decoder, key_encoder):\n",
        "    query_decoder = tf.expand_dims(query_decoder, 1)\n",
        "    o = tf.keras.activations.tanh(\n",
        "            self.W1(query_decoder) + self.W2(key_encoder))\n",
        "    o = self.V(o)\n",
        "    attention_weights = self.softmax(o)\n",
        "    temp = tf.reduce_sum(attention_weights * key_encoder, axis=1)\n",
        "    context_vector = tf.expand_dims(temp, axis=1)\n",
        "    return attention_weights, context_vector\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, units, vocab_size, emb_dims):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.lstm_layer = LSTM(units, return_state=True, return_sequences=True)\n",
        "    self.embedding_layer = Embedding(vocab_size, \n",
        "                                     emb_dims, \n",
        "                                     mask_zero=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs = self.embedding_layer(inputs)\n",
        "    hidden_state_sequence, final_hidden_state, final_cell_state = self.lstm_layer(inputs)\n",
        "    final_states = [final_hidden_state, final_cell_state]\n",
        "    return hidden_state_sequence, final_states\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, units, vocab_size, emb_dims):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.lstm_layer = LSTM(units, return_state=True, return_sequences=True)\n",
        "    self.embedding_layer = Embedding(vocab_size, \n",
        "                                     emb_dims, \n",
        "                                     mask_zero=True)\n",
        "    self.output_layer = Dense(vocab_size)\n",
        "\n",
        "  def call(self, \n",
        "           inputs, \n",
        "           context_vector,\n",
        "           previous_states):\n",
        "\n",
        "    if len(inputs.shape) == 1:\n",
        "      inputs = tf.expand_dims(inputs, axis=1)\n",
        "    inputs = self.embedding_layer(inputs)\n",
        "    inputs = tf.concat([inputs, context_vector], axis=-1)\n",
        "    _, next_hidden_state, next_cell_state = self.lstm_layer(inputs, \\\n",
        "                                            initial_state=previous_states)\n",
        "    output = self.output_layer(next_hidden_state)\n",
        "    next_states = [next_hidden_state, next_cell_state]\n",
        "    return next_states, output\n",
        "\n",
        "\n",
        "class NMT(tf.keras.Model):\n",
        "  def __init__(self, units, \n",
        "               enc_vocab_size, \n",
        "               dec_vocab_size,\n",
        "               emb_dims, \n",
        "               attention_hidden_dims, \n",
        "               decoder_tokenizer):\n",
        "    \n",
        "    super(NMT, self).__init__()\n",
        "    self.units = units\n",
        "    self.encoder = Encoder(units, enc_vocab_size, emb_dims)\n",
        "    self.decoder = Decoder(units, dec_vocab_size, emb_dims)\n",
        "    self.attention_layer = AttentionLayer(attention_hidden_dims)\n",
        "    self.decoder_tokenizer = decoder_tokenizer\n",
        "\n",
        "  def call(self, \n",
        "           inputss,\n",
        "           targets,\n",
        "           eval=False):\n",
        "\n",
        "      bs, _ = inputss.shape\n",
        "      loss = 0\n",
        "      hidden_state_sequence, input_states = self.encoder(inputs)\n",
        "      query_decoder = input_states[0] # select hidden state\n",
        "      predicted_outputs = []\n",
        "      attention_weights_list = []\n",
        "      \n",
        "      dec_input = self.decoder_tokenizer.texts_to_sequences(['<start>'])\n",
        "      dec_input = tf.constant(dec_input * bs)\n",
        "      num_target_timesteps = targets.shape[1]\n",
        "\n",
        "      for i in range(1, num_target_timesteps):\n",
        "        attention_weights, context_vector = self.attention_layer(query_decoder, hidden_state_sequence)\n",
        "        input_states, outputs = self.decoder(dec_input, context_vector, input_states)\n",
        "        if eval:\n",
        "          dec_input = tf.argmax(outputs, axis=1)\n",
        "        else:\n",
        "          dec_input = targets[:, i] # dec input for next stage is target for this stage\n",
        "\n",
        "        query_decoder = input_states[0]\n",
        "        loss += loss_fn(dec_input, outputs)\n",
        "        \n",
        "        \n",
        "        if eval:\n",
        "          predictions = tf.expand_dims(dec_input, 1)\n",
        "          predictions = self.decoder_tokenizer.sequences_to_texts(predictions.numpy())\n",
        "          predicted_outputs.append(predictions)\n",
        "          attention_weights_list.append(attention_weights.numpy())\n",
        "\n",
        "      loss /= num_target_timesteps\n",
        "\n",
        "      if len(attention_weights_list) != 0:\n",
        "        predicted_outputs = np.array(predicted_outputs).T\n",
        "        attention_weights = np.stack(attention_weights_list, axis=2)[..., -1]\n",
        "                                      \n",
        "      return loss, predicted_outputs, attention_weights\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P6Lh2Dku5i2"
      },
      "source": [
        "sparse_cat_lossfn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_model(model, optimizer, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, prediction, attention_weights = model(inputs, targets)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss, prediction, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMmbHBzUuZKQ"
      },
      "source": [
        "## Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olKX672luYUx"
      },
      "source": [
        "checkpoint_directory = \"./checkpoints\"\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "nmt_model = NMT(UNITS, VOCAB_INP_SIZE, VOCAB_TARG_SIZE, EMBED_DIMS, ATTENTION_DIMS, french_tokenizer)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, nmt_model=nmt_model)\n",
        "manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=checkpoint_directory, max_to_keep=2)\n",
        "\n",
        "status = checkpoint.restore(manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vTW86SCx32U",
        "outputId": "dbf27bba-154b-4c00-b925-5d475dbc3465"
      },
      "source": [
        "resume_epoch = max([1] + [int(i.split('.')[0].split(\"-\")[1]) \\\n",
        "                          for i in os.listdir('checkpoints') \\\n",
        "                          if 'ckpt' in i])\n",
        "\n",
        "for epoch in range(resume_epoch, EPOCHS + 1):\n",
        "  train_epoch_loss = []\n",
        "  val_epoch_loss = []\n",
        "  attention_weights_list = []\n",
        "  prediction_list = []\n",
        "  for i, (inp, targ) in enumerate(train_data):\n",
        "    loss, _, _ = train_model(nmt_model, optimizer, inp, targ)\n",
        "    train_epoch_loss.append(loss.numpy())\n",
        "\n",
        "  for i, (inp, targ) in enumerate(test_data):\n",
        "    loss, prediction, attention_weights = nmt_model(inp, targ, eval=True)\n",
        "    attention_weights_list.append(attention_weights)\n",
        "    prediction_list.append(prediction)\n",
        "    val_epoch_loss.append(loss.numpy())\n",
        "  \n",
        "  inp_text = english_tokenizer.sequences_to_texts(inp.numpy())\n",
        "  targ_text = nmt_model.decoder_tokenizer.sequences_to_texts(targ.numpy())\n",
        "\n",
        "  #status.assert_consumed()  # Optional sanity checks.\n",
        "  manager.save()\n",
        "\n",
        "  for idx in np.random.randint(0, len(inp_text), 5):\n",
        "    prediction_text = \" \".join(list(prediction[idx]))\n",
        "    print(f\"input: {disp_sentence(inp_text[idx])}\")\n",
        "    print(f\"target: {disp_sentence(targ_text[idx])}\")\n",
        "    print(f\"prediction: {prediction_text} \\n\")\n",
        "  \n",
        "  train_epoch_loss = np.mean(train_epoch_loss)\n",
        "  val_epoch_loss = np.mean(val_epoch_loss)\n",
        "  print(f\"Epoch {epoch}, train loss: {train_epoch_loss} val loss: {val_epoch_loss}\\n\")\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method Tokenizer.texts_to_sequences_generator of <keras_preprocessing.text.Tokenizer object at 0x7fd5fa5e8630>> appears to be a generator function. It will not be converted by AutoGraph.\n",
            "WARNING: Entity <bound method Tokenizer.texts_to_sequences_generator of <keras_preprocessing.text.Tokenizer object at 0x7fd5fa5e8630>> appears to be a generator function. It will not be converted by AutoGraph.\n",
            "input: can you make out the meaning easily ?\n",
            "target: peux-tu facilement en dire le sens ?\n",
            "prediction: peux-tu facilement le sens ? <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "input: i'm not from around here .\n",
            "target: je ne suis pas du coin .\n",
            "prediction: je ne suis pas en securite , ici . <end> . <end> <end> . <end> . <end> <end> . <end> . <end> <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: he was found mysteriously murdered .\n",
            "target: on l'a trouve mysterieusement assassine .\n",
            "prediction: il fut fait des progres a le coup de le voyage . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: are you ready to go out ?\n",
            "target: etes-vous prete a sortir ?\n",
            "prediction: etes-vous pret a sortir ? <end> <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! \n",
            "\n",
            "input: i like cats .\n",
            "target: j’aime les chats .\n",
            "prediction: j'aime les chats . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "Epoch 15, train loss: 0.3069606125354767 val loss: 0.2675207257270813\n",
            "\n",
            "input: maybe we can fix this .\n",
            "target: nous pouvons peut-etre reparer ceci .\n",
            "prediction: peut-etre pouvons-nous le reparer . <end> . <end> . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: do you eat rice every day ?\n",
            "target: mangez-vous du riz tous les jours ?\n",
            "prediction: manges-tu du jour de mer tous les jours ? <end> <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: just out of curiosity , what do you expect to happen ?\n",
            "target: juste par curiosite , qu'attendez-vous qu'il se passe ?\n",
            "prediction: est-ce que ca peut faire de la maniere dont vous faites me faire du souci ? <end> , oui . <end> <end> ? <end> <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . \n",
            "\n",
            "input: tom asked mary not to do anything .\n",
            "target: tom demanda a mary de ne pas intervenir .\n",
            "prediction: tom a demande a mary de ne pas faire cela . <end> . <end> . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: i think they did it on purpose .\n",
            "target: je pense qu'ils l'ont fait expres .\n",
            "prediction: je pense qu'elles l'ont fait expres . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "Epoch 16, train loss: 0.1553916186094284 val loss: 0.2565752863883972\n",
            "\n",
            "input: don't call me a jerk .\n",
            "target: ne me traite pas de pauvre type !\n",
            "prediction: ne me charriez pas une . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: what shall we eat tonight ?\n",
            "target: qu'allons-nous manger ce soir ?\n",
            "prediction: que manger de ce soir ? <end> ? <end> ? <end> <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ? <end> \n",
            "\n",
            "input: men differ from other animals in that they can think and speak .\n",
            "target: les hommes different des autres animaux en cela qu'ils peuvent penser et parler .\n",
            "prediction: les hommes hommes sont ne plus en bonne sante et on en a besoin . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: let's end this .\n",
            "target: terminons ceci .\n",
            "prediction: finissons-en . <end> . <end> <end> ! <end> <end> ! <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: why is there no hot water ?\n",
            "target: pourquoi n'y a-t-il pas d'eau chaude  ?\n",
            "prediction: pourquoi n'y a-t-il pas d'eau ? <end> ? <end> <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> des miennes . <end> <end> des des armes ! <end> <end> des des armes ? <end> <end> des armes . <end> <end> des autres . <end> <end> . <end> <end> des autres . <end> <end> . <end> \n",
            "\n",
            "Epoch 17, train loss: 0.07317346334457397 val loss: 0.20024235546588898\n",
            "\n",
            "input: how nice !\n",
            "target: comme c'est gentil !\n",
            "prediction: comme c'est agreable ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "input: i should have brought a lunch .\n",
            "target: j'aurais du amener un dejeuner .\n",
            "prediction: j'aurais du payer le chocolat . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: i am much obliged to you for your help .\n",
            "target: j'apprecie beaucoup votre aide .\n",
            "prediction: j'ai une absolue t'aider pour toi . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: i bought the book for ten dollars .\n",
            "target: j'ai achete le livre pour dix dollars .\n",
            "prediction: j'ai achete le livre pour dix dollars . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: i fear no one .\n",
            "target: je ne crains personne .\n",
            "prediction: je n'en ai pas beaucoup . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "Epoch 18, train loss: 0.0348830446600914 val loss: 0.12426547706127167\n",
            "\n",
            "input: you're weird .\n",
            "target: vous etes bizarre .\n",
            "prediction: vous etes bizarre . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: i saw her home .\n",
            "target: je l'ai vue a la maison .\n",
            "prediction: je l'ai vu la maison . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: things took a sudden turn for the worse .\n",
            "target: les choses prirent soudain une mauvaise tournure .\n",
            "prediction: les choses prirent une idee de ce qu'ils font . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: mastering a foreign language is difficult .\n",
            "target: maitriser une langue etrangere est difficile .\n",
            "prediction: maitriser un emploi de passe est difficile . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: even a child can do that .\n",
            "target: meme un enfant peut faire ca .\n",
            "prediction: meme un enfant peut faire ca . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "Epoch 19, train loss: 0.02061116136610508 val loss: 0.14376112818717957\n",
            "\n",
            "input: i've already eaten breakfast .\n",
            "target: j'ai deja mange mon petit dejeuner .\n",
            "prediction: j'ai deja mange le petit-dejeuner . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: we had a wonderful weekend .\n",
            "target: nous avons eu un week-end merveilleux .\n",
            "prediction: nous avons eu un bon velo . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: you'll make the same mistake if things continue in this way .\n",
            "target: tu commettras la meme erreur si les choses se poursuivent ainsi .\n",
            "prediction: vous aurez le meme probleme a cette facon , pour ce poste . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: have you finished it ?\n",
            "target: l'as-tu termine  ?\n",
            "prediction: avez-vous termine ca  ? <end> <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "input: you don't understand the procedure .\n",
            "target: tu ne comprends pas la procedure .\n",
            "prediction: vous ne comprenez pas le systeme . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "Epoch 20, train loss: 0.015394499525427818 val loss: 0.10646183043718338\n",
            "\n",
            "input: this is the worst book i've ever read .\n",
            "target: c'est le plus mauvais de tous les livres que j'ai lus jusqu'a maintenant .\n",
            "prediction: c'est le meilleur livre que j'ai jamais vu . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: tom broke his arm .\n",
            "target: tom s'est casse le bras .\n",
            "prediction: tom s'est casse le bras . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: he was jealous of their happiness .\n",
            "target: il etait jaloux de leur bonheur .\n",
            "prediction: il etait jaloux de leur bonheur . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: i can hear nothing .\n",
            "target: je n'entends rien .\n",
            "prediction: j'entends quoi que ce soit . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: who's that girl ?\n",
            "target: qui est cette fille  ?\n",
            "prediction: qui est cette fille ? <end> ? <end> <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "Epoch 21, train loss: 0.013858981430530548 val loss: 0.11261606961488724\n",
            "\n",
            "input: we could watch a movie .\n",
            "target: nous pourrions regarder un film .\n",
            "prediction: nous pourrions peut-etre vu un film . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: we could watch a movie .\n",
            "target: nous pourrions regarder un film .\n",
            "prediction: nous pourrions peut-etre vu un film . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: i love this view .\n",
            "target: j'adore cette vue .\n",
            "prediction: j'adore ce coup de ca . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: tom did something strange .\n",
            "target: tom a fait quelque chose d'etrange .\n",
            "prediction: tom a fait quelque chose de mal . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: i think that he is right .\n",
            "target: je pense qu'il a raison .\n",
            "prediction: je pense qu'il a raison . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "Epoch 22, train loss: 0.013453741557896137 val loss: 0.14413073658943176\n",
            "\n",
            "input: i'm being promoted .\n",
            "target: on m'a promu .\n",
            "prediction: j'ai la schcoumoune . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: that was really weird .\n",
            "target: c'etait vraiment bizarre .\n",
            "prediction: c'etait vraiment bizarre . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: it's a fake one , right ?\n",
            "target: c'est un faux , non  ?\n",
            "prediction: c'est une contrefacon , n'est-ce pas  ? <end> ? <end> <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: are you productive ?\n",
            "target: etes-vous productives ?\n",
            "prediction: etes-vous productive ? <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! \n",
            "\n",
            "input: are you productive ?\n",
            "target: etes-vous productives ?\n",
            "prediction: etes-vous productive ? <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! \n",
            "\n",
            "Epoch 23, train loss: 0.01403333805501461 val loss: 0.10205650329589844\n",
            "\n",
            "input: did you show it to your parents ?\n",
            "target: l'as-tu montre a tes parents  ?\n",
            "prediction: as-tu termine de tes parents ? <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: why did you like it ?\n",
            "target: pourquoi l'avez-vous aime ?\n",
            "prediction: pourquoi as-tu recrutee ? <end> ? <end> <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ? <end> <end> . <end> <end> ! <end> <end> \n",
            "\n",
            "input: i don't want to shoot you .\n",
            "target: je ne veux pas vous descendre .\n",
            "prediction: je ne veux pas vous tirer dessus . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: tom tore the paper in half .\n",
            "target: tom dechira le papier en deux .\n",
            "prediction: tom a vu le journal en marche . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: don't worry . this won't happen again .\n",
            "target: ne vous faites pas de souci ! ca n'arrivera plus .\n",
            "prediction: ne vous en faites pas ! vous n'auriez pas a faire ca . <end> . <end> . <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "Epoch 24, train loss: 0.01367599330842495 val loss: 0.1450556516647339\n",
            "\n",
            "input: i guess you heard about what happened this morning .\n",
            "target: je suppose que vous avez entendu dire ce qui s'est passe ce matin .\n",
            "prediction: je suppose que vous avez entendu cette question a ce sujet s'est passe . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: don't drink the tap water .\n",
            "target: ne buvez pas l'eau du robinet .\n",
            "prediction: ne bois pas la vitre fermee ! <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> . <end> <end> ! <end> \n",
            "\n",
            "input: i'm being careful .\n",
            "target: je fais attention .\n",
            "prediction: je suis prudent . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: why are you dressed like that ?\n",
            "target: pourquoi etes-vous habilles comme cela ?\n",
            "prediction: pourquoi es-tu habille comme ca ? <end> ? <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "input: don't drink the tap water .\n",
            "target: ne buvez pas l'eau du robinet .\n",
            "prediction: ne bois pas la vitre fermee ! <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> . <end> <end> ! <end> \n",
            "\n",
            "Epoch 25, train loss: 0.012698925100266933 val loss: 0.10714513808488846\n",
            "\n",
            "input: there's no reason to panic .\n",
            "target: il n'y a aucune raison de ceder a la panique .\n",
            "prediction: il n'y a aucune raison de se presser . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: many revolutions have aimed to abolish the aristocracy .\n",
            "target: de nombreuses revolutions ont eu pour but d'abolir l'aristocratie .\n",
            "prediction: beaucoup de clients sur le gouvernement a porter plainte . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: she warned the children not to play on the street .\n",
            "target: elle avertit les enfants de ne pas jouer dans la rue .\n",
            "prediction: elle a marie a les enfants de ne pas nager au cinema . <end> . <end> . <end> . <end> <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> \n",
            "\n",
            "input: they released tom .\n",
            "target: elles ont relache tom .\n",
            "prediction: elles ont deporte tom . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: this elevator is out of order . please use the stairs .\n",
            "target: l'ascenseur est en panne . merci d'utiliser les escaliers .\n",
            "prediction: ce chapeau est impossible de conduire dans des vetements . <end> . <end> les notres . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "Epoch 26, train loss: 0.01114632561802864 val loss: 0.1098085269331932\n",
            "\n",
            "input: was the baby crying then ?\n",
            "target: le bebe pleurait-il a ce moment-la  ?\n",
            "prediction: le bebe me laisse pleurer ? <end> ? <end> <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: he was not conscious of his own mistake .\n",
            "target: il n'etait pas conscient de sa propre erreur .\n",
            "prediction: il n'etait pas conscient de son ami . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> \n",
            "\n",
            "input: it's just a scratch , ok ?\n",
            "target: c'est juste une egratignure , d'accord ?\n",
            "prediction: ce n'est qu'une , n'est-ce pas  ? <end> , un ? <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: he was not conscious of his own mistake .\n",
            "target: il n'etait pas conscient de sa propre erreur .\n",
            "prediction: il n'etait pas conscient de son ami . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> \n",
            "\n",
            "input: children don't always listen to their parents .\n",
            "target: les enfants n'ecoutent pas toujours leurs parents .\n",
            "prediction: les parents ont toujours de bonnes leurs parents . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "Epoch 27, train loss: 0.010206956416368484 val loss: 0.10344652086496353\n",
            "\n",
            "input: i didn't even know tom had a girlfriend .\n",
            "target: je ne savais meme pas que tom avait une petite amie .\n",
            "prediction: je ne savais meme pas que ma copine . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: are you allowed to go ?\n",
            "target: vous est-il permis de vous y rendre ?\n",
            "prediction: t'est-il permis d'y aller ? <end> ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "input: are you sure you're not tired ?\n",
            "target: es-tu sur de ne pas etre fatigue ?\n",
            "prediction: etes-vous sures que vous n'etes pas fatigues ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> ? <end> <end> . <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> . <end> <end> . <end> <end> . <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! \n",
            "\n",
            "input: how about going to the movies on saturday ?\n",
            "target: que diriez-vous d'aller au cinema samedi ?\n",
            "prediction: et si vous couriez  a la reunion ? <end> ? <end> <end> ? <end> <end> ? <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> <end> ! <end> \n",
            "\n",
            "input: i did something i regret doing .\n",
            "target: j'ai fait quelque chose que je regrette d'avoir fait .\n",
            "prediction: j'ai autre chose en faire . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "Epoch 28, train loss: 0.009835583157837391 val loss: 0.1035919338464737\n",
            "\n",
            "input: i meet him at the club .\n",
            "target: je le rencontre au club .\n",
            "prediction: je l'ai vu au club . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> \n",
            "\n",
            "input: if i'd known it , i'd have told you .\n",
            "target: l'aurais-je su , je te l'aurais dit .\n",
            "prediction: si je le dirais , je le dirais . <end> . <end> . <end> <end> . » <end> ! <end> <end> . <end> <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » <end> . » \n",
            "\n",
            "input: does he like me ?\n",
            "target: m'apprecie-t-il ?\n",
            "prediction: aimerait-il ? <end> ? <end> ? <end> ? <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: i want kids .\n",
            "target: je veux des enfants .\n",
            "prediction: je veux des enfants . <end> . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: try to find it .\n",
            "target: essaie de le trouver .\n",
            "prediction: essaie de le reparer . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . \n",
            "\n",
            "Epoch 29, train loss: 0.010079678148031235 val loss: 0.14988619089126587\n",
            "\n",
            "input: i thought they were wrong .\n",
            "target: je pensais qu'elles avaient tort .\n",
            "prediction: je pensais qu'elles etaient satisfaits . <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: stop being so naive .\n",
            "target: arrete d'etre si naive .\n",
            "prediction: arretez d'etre si naive . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: how about tonight ?\n",
            "target: que dites-vous de cette nuit ?\n",
            "prediction: que dites-vous de ce soir ? <end> ? <end> <end> ? <end> <end> ? <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: i never get to see you anymore .\n",
            "target: je n'ai plus l'occasion de te voir .\n",
            "prediction: je ne vous dois plus vous revoir . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . <end> . \n",
            "\n",
            "input: perhaps he'll never become famous .\n",
            "target: peut-etre qu'il ne deviendra jamais celebre .\n",
            "prediction: peut-etre ne pourrait jamais etre en vie . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » <end> .  » \n",
            "\n",
            "Epoch 30, train loss: 0.0107096703723073 val loss: 0.1208881065249443\n",
            "\n",
            "input: they accused him of telling a lie .\n",
            "target: elles l'ont accuse de dire un mensonge .\n",
            "prediction: elles ont ete en tete pour un mensonge . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: i was offended .\n",
            "target: j'ai ete offense .\n",
            "prediction: j'ai ete offensee . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> \n",
            "\n",
            "input: your death will not have been in vain .\n",
            "target: votre mort n'aura pas ete vaine .\n",
            "prediction: votre mort ne disposait pas de la mort . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "input: i have a few tickets in row 15 .\n",
            "target: j'ai quelques entrees pour la rangee 15 .\n",
            "prediction: j'ai quelques minutes dans les bois . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> \n",
            "\n",
            "input: she had a good time talking with him about his trip .\n",
            "target: elle a passe un agreable moment a s'entretenir avec lui au sujet de son voyage .\n",
            "prediction: elle a passe un agreable moment a discuter avec lui a propos de son voyage . <end> <end> . <end> . <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . <end> <end> . \n",
            "\n",
            "Epoch 31, train loss: 0.010175878182053566 val loss: 0.09207324683666229\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0VxEdN0uAF"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkRUf8X7zovg"
      },
      "source": [
        "def prep_text_for_eval(x, tokenizer=english_tokenizer):\n",
        "  list_of_sentences = x.split(\".\")\n",
        "  list_of_sentences = [sen + \".\" for sen in list_of_sentences]\n",
        "  inp = [preprocess_sentence(i) for i in list_of_sentences]\n",
        "  inp = tokenizer.texts_to_sequences(inp)\n",
        "  inp = pad_sequences(inp, maxlen= NUM_INP_TIMESTEPS, padding='post')\n",
        "  return inp\n",
        "\n",
        "def display_prediction(prediction):\n",
        "  pred = []\n",
        "  for line in prediction:\n",
        "    pred_index = np.where(line == '<end>')[0][0]\n",
        "    pred.extend(list(line[:pred_index]))\n",
        "  return \" \".join(pred)\n",
        "\n",
        "def query_preprocessor(inp, english_tokenizer=english_tokenizer):\n",
        "  if tf.is_tensor(inp):\n",
        "    query = english_tokenizer.sequences_to_texts(inp.numpy())\n",
        "    query = np.array(query)\n",
        "  elif type(inp) is np.ndarray and np.issubdtype(inp.dtype, np.integer):\n",
        "    query = english_tokenizer.sequences_to_texts(inp)\n",
        "    \n",
        "  return query"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6yxxZWT-ofZ"
      },
      "source": [
        "def display_attention(query, attention, prediction, base_size):\n",
        "  \n",
        "  num_plots, query_size, pred_size = attention.shape\n",
        "  \n",
        "  num_rows = num_plots//2 if num_plots % 2 == 0 else num_plots//2 + 1\n",
        "  rows = base_size * num_rows\n",
        "  cols = 2 * base_size\n",
        "  fig = plt.figure(figsize=(rows, cols))\n",
        "  \n",
        "  input_sentences = []\n",
        "  for i in range(1, num_plots + 1):\n",
        "    \n",
        "    pred = prediction[i-1]\n",
        "    pred_index = np.where(pred == '<end>')[0][0]\n",
        "    pred = pred[:pred_index]\n",
        "    \n",
        "    \n",
        "    que = query[i-1].split(\" \")\n",
        "    query_index = que.index('<end>') if '<end>' in que else len(que)\n",
        "    que = np.array(que)[1:query_index]\n",
        "    input_sentences.append(\" \".join(que))\n",
        "    \n",
        "    att_matrix = attention[i-1]\n",
        "    att_matrix = att_matrix[1:query_index,:pred_index]\n",
        "    \n",
        "\n",
        "    ax = fig.add_subplot(num_rows, 2, i)\n",
        "    ax.matshow(att_matrix, cmap='viridis')\n",
        "    ax.set_xticks(np.arange(len(pred)))\n",
        "    ax.set_yticks(np.arange(len(que)))\n",
        "    ax.set_xticklabels(pred)\n",
        "    ax.set_yticklabels(que)\n",
        "\n",
        "  input_sentences = \" \".join(input_sentences)\n",
        "  print(f\"input: {input_sentences}\")\n",
        "  plt.show()\n",
        "\n",
        "def prep_and_eval(inp, targ=None, base_size=10):\n",
        "  if type(inp) is str:\n",
        "    inp = prep_text_for_eval(inp)\n",
        "    if targ is None:\n",
        "      targ = inp\n",
        "\n",
        "  _, prediction, attention = nmt_model(inp, targ, eval=True)\n",
        "  query = query_preprocessor(inp)\n",
        "  print(f\"prediction: {display_prediction(prediction)}\")\n",
        "  display_attention(query, attention, prediction, base_size)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKXbNo95Cj_r"
      },
      "source": [
        "## Random Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "u-47bsrH0nYZ",
        "outputId": "3ca060e4-1836-47a0-ca0b-9b9a8aafc214"
      },
      "source": [
        "input_sentence = \"what is your name. I want to know you\"\n",
        "prep_and_eval(input_sentence)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction: quel est ton nom ? je veux savoir vous .\n",
            "input: what is your name . i want to know you .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x1440 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc8x3mDJ9IpG"
      },
      "source": [
        "test_data_ = test_data.take(5)\n",
        "sample_test_data = list(test_data.as_numpy_iterator())"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm376gFrCnnq"
      },
      "source": [
        "## Test set input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "d4MLFy729v4O",
        "outputId": "5e736a68-5286-4594-b4f9-7a356a793e45"
      },
      "source": [
        "idx = 2\n",
        "num_samples = 2\n",
        "inp, targ = sample_test_data[idx]\n",
        "inp = inp[:num_samples]\n",
        "targ = inp[:num_samples]\n",
        "prep_and_eval(inp, targ, 15)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction: il te faut garder des œufs sur de beaux endroits et de te suis revenu . je me suis leve plus tot que d'habitude afin d'attraper le premier train .\n",
            "input: you need to wear thick socks to keep your feet warm . i got up earlier than usual in order to catch the first train .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x2160 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QexCaZNn_btF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}